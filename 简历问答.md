



**项目一：基于思维链启发的大模型推理能力增强研究 (本科科研训练)**

1.  **目标与思路:**
    *   请详细介绍一下这个项目的立项背景和具体目标。"借鉴 CoT/ToT 思想" 具体是指借鉴了哪些核心点？你是如何构思通过 SFT (LoRA) 的方式来实现这种思想的？
        *   ToT将问题建模为树状 搜索过程，问题分解、想法生成，状态评价以及搜索算法的选择
        *   propose prompt：方案有限（状态有限的搜索）
        *   利用LM对现有状态进行评估。进行投票选择
    *   为什么选择 Llama-2 作为基础模型？为什么选择类 24 点数学推理任务？这个任务有什么特别的挑战吗？
        *   24点任务方便评估和合成数据，并且有一定的实际价值
        *   Llama2 作为基模型好训练
2.  **数据工程:**
    *   你提到设计并实现了“合成推理步骤数据自动化脚本”。能具体描述一下这个脚本生成的数据格式是怎样的吗？（例如，是 `问题 -> 推理步骤 -> 答案` 的格式吗？）
        *   
    *   生成合成数据的过程中，你遇到了哪些挑战？如何保证生成数据的质量和多样性？
        *   
        *   加入符号约束等，限制中间结果
3.  **模型微调 (LoRA):**
    *   你能简单解释一下 LoRA 的工作原理吗？相比于全参数微调，它有什么优势和劣势？
        *   Lora的核心思想是用较小的学习参数改变性能。它将原本维度为d*d矩阵，表示为(d,r)和(r,d)两个矩阵从而将参数减少
        *   r
    *   在 Llama-2 LoRA 微调实验中，你是如何选择 LoRA 的关键超参数（如 `r`, `lora_alpha`, `target_modules`）的？有没有做消融实验来验证参数选择的合理性？
    *   你提到了“熟悉服务器训练流程”，能分享一下在训练过程中遇到过哪些工程上的挑战（如显存管理、训练效率、分布式训练等）以及你是如何解决的吗？
4.  **实验评估:**
    *   “自动化评估脚本”是如何实现的？它主要评估哪些指标？除了准确率，有没有关注其他方面，比如推理步骤的合理性？
    *   在进行对比实验时，你是如何设置 Baseline 的？最终 SFT (LoRA) 的效果相比 Baseline 提升了多少？
5.  **成果与反思:**
    *   你提到了“实践了 LLM 微调与评估全流程”并尝试投稿 EMNLP。在这个过程中，你认为最有挑战性的部分是什么？最大的收获是什么？
    *   如果现在让你重新做这个项目，你会考虑哪些不同的方法或改进点？

**项目二：LLM 推理增强策略研究 (NLP 课设)**

1.  **策略实现:**
    *   请具体解释一下你实现的 CoT、Voting 和 IR 增强 CoT 策略。特别是 "Voting" 策略，是如何对多个推理路径或结果进行投票的？
    *   你实现的 "IR 增强 CoT" 与 RAG (Retrieval-Augmented Generation) 和 ReAct (Reasoning and Acting) 的思想有哪些共通之处和区别？这里的 "IR" (Information Retrieval) 是如何实现的？检索的数据源是什么？
2.  **实验设计与分析:**
    *   为什么选择 GLM-3/DeepSeek 这两个模型进行研究？选择 AQuA 数据集的理由是什么？
    *   你是如何进行“成本效益分析”的？具体是如何量化“成本”（Token 消耗？）和“效益”（准确率？）的？
    *   最终验证了 "IR+CoT 策略的有效性与成本优势"，这个结论是基于哪些具体的实验数据得出的？相比单独使用 CoT 或 Voting，它的优势体现在哪些方面？

**项目三：高效蛋白质相似度检索算法 (数据挖掘课设)**

1.  **算法创新:**
    *   这个项目和 LLM 看似关联不大，但展现了你在算法设计和优化方面的能力。你能详细解释一下你提出的“结合窗口词频与 N-gram 的特征提取算法”吗？它相比于 Baseline 的 CNN 特征提取，核心的创新点或优势是什么？
    *   为什么想到用这种方法替代 CNN？是基于对蛋白质序列数据特性的理解吗？
2.  **性能提升:**
    *   准确率 (Top-1 Acc, Avg Acc) 和速度都得到了显著提升。你认为哪个因素（窗口词频？N-gram？两者的结合方式？）对性能提升的贡献最大？
    *   你是如何在保证准确率提升的同时，将处理时间从 >3 分钟缩短到 <1 分钟的？

**通用问题:**

*   在你参与的这些项目中，哪个项目让你觉得技术挑战最大？你是如何克服这些挑战的？
*   你对 LLM 的未来发展方向有什么看法？特别是在推理能力增强和 Agent 应用方面？
*   结合你的项目经验，你认为构建一个强大的 AI Agent 系统，最关键的技术点和挑战是什么？

这些问题旨在深入了解你的技术深度、解决问题的能力、思考过程以及对相关领域的理解。请准备好详细阐述你的项目细节和思考过程。祝你面试顺利！