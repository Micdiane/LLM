{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "847d231c",
   "metadata": {},
   "source": [
    "# ‰ΩøÁî®Ê®°ÂûãÔºåÊó†ËÆ∞ÂøÜÁöÑÂæ™ÁéØËÅäÂ§©Ê®°Âºè\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b27ac70b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.messages import HumanMessage\n",
    "from langchain_openai import ChatOpenAI\n",
    "APIKEY = input()\n",
    "model = ChatOpenAI(\n",
    "    base_url=\"https://openrouter.ai/api/v1\",\n",
    "    api_key=APIKEY,\n",
    "    model=\"thudm/glm-4-32b:free\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0cc0fcd1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Hi Bob! How can I assist you today?\n",
      "\n",
      "Sorry, I cannot answer this question. As an AI assistant, I don't have any information about myself, including who I am. My goal is to help users get answers they need by providing objective information. If you have any questions, you can ask me anytime, and I'll try my best to provide useful answers.\n",
      "\n",
      "BYD is a large China-based manufacturer that produces a variety of products, including cell phones, batteries, electronics, automobiles, and buses. It is also heavily investing in new energy vehicles (NEVs) and renewable energy solutions.\n",
      "\n",
      "It was founded in February 1995 by Wang Chuanfu.\n",
      "It is headquartered in Shenzhen, Guangdong.\n",
      "BYD means Build Your Dreams.\n",
      "\n",
      "It is one of the world's largest manufacturers of rechargeable batteries.\n",
      "It has the world's largest installed capacity of solar power panels.\n",
      "It is also one of the largest Chinese automakers.\n",
      "It also provides solutions for rail transit.\n",
      "\n",
      "So, what specifically would you like to know about BYD? I can provide more information on its products, services, financial performance, research and development, etc.\n",
      "\n",
      "Bye üëã! If you have any more questions in the future, feel free to reach out!\n",
      "Exiting the chat. Goodbye!\n"
     ]
    }
   ],
   "source": [
    "from langchain_core.output_parsers import StrOutputParser\n",
    "demochain = model | StrOutputParser() \n",
    "while True:\n",
    "    user_input = input(\"You: \")\n",
    "    print(demochain.invoke(\n",
    "        [HumanMessage(content=user_input)]\n",
    "    ))\n",
    "    if user_input.lower() in [\"exit\", \"quit\", \"bye\"]:\n",
    "        print(\"Exiting the chat. Goodbye!\")\n",
    "        break"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6197e080",
   "metadata": {},
   "source": [
    "# ËÆ©Ê®°ÂûãËÆ∞‰Ωè‰πãÂâçËÅäËøá‰ªÄ‰πà"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "98a96e85",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.chat_history import BaseChatMessageHistory,InMemoryChatMessageHistory\n",
    "from langchain_core.runnables.history import RunnableWithMessageHistory\n",
    "store = {}\n",
    "def getSessionHistory(session_id):\n",
    "    if session_id not in store:\n",
    "        store[session_id] = InMemoryChatMessageHistory()\n",
    "    return store[session_id]\n",
    "with_history = RunnableWithMessageHistory(model, get_session_history=getSessionHistory)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "23ae18d8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "content='\\nHello üëã, Bob! Really happy to meet you! If you have any questions or need help, please feel free to tell me.' additional_kwargs={'refusal': None} response_metadata={'token_usage': {'completion_tokens': 30, 'prompt_tokens': 8, 'total_tokens': 38, 'completion_tokens_details': None, 'prompt_tokens_details': None}, 'model_name': 'thudm/glm-4-32b:free', 'system_fingerprint': None, 'id': 'gen-1748391309-MWeOj4nwoexGeBMboo6L', 'finish_reason': 'stop', 'logprobs': None} id='run-ae149abb-6401-4188-a04e-851ae16ebfc2-0' usage_metadata={'input_tokens': 8, 'output_tokens': 30, 'total_tokens': 38, 'input_token_details': {}, 'output_token_details': {}}\n",
      "content='\\nYour name is Bob.' additional_kwargs={'refusal': None} response_metadata={'token_usage': {'completion_tokens': 7, 'prompt_tokens': 45, 'total_tokens': 52, 'completion_tokens_details': None, 'prompt_tokens_details': None}, 'model_name': 'thudm/glm-4-32b:free', 'system_fingerprint': None, 'id': 'gen-1748391313-U59aBtWxwbVZ88Rxs3ib', 'finish_reason': 'stop', 'logprobs': None} id='run-a0c38d33-f4e8-404f-804d-3b8532de3415-0' usage_metadata={'input_tokens': 45, 'output_tokens': 7, 'total_tokens': 52, 'input_token_details': {}, 'output_token_details': {}}\n"
     ]
    }
   ],
   "source": [
    "Bob_config = {\"configurable\": {\"session_id\": \"Bob\"}}\n",
    "res = with_history.invoke(\n",
    "    [HumanMessage(content=\"I am Bob\")],\n",
    "    config=Bob_config\n",
    ")\n",
    "print(res)\n",
    "res = with_history.invoke(\n",
    "    [HumanMessage(content=\"What is my name?\")],\n",
    "    config=Bob_config\n",
    ")\n",
    "print(res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "15e53791",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "content=\"\\nYou haven't told me what your name is yet. Could you please share it?\" additional_kwargs={'refusal': None} response_metadata={'token_usage': {'completion_tokens': 19, 'prompt_tokens': 145, 'total_tokens': 164, 'completion_tokens_details': None, 'prompt_tokens_details': None}, 'model_name': 'thudm/glm-4-32b:free', 'system_fingerprint': None, 'id': 'gen-1748391460-d0tMuRoUP3cXS9z4e06b', 'finish_reason': 'stop', 'logprobs': None} id='run-6d08cffd-35bb-44f2-a96d-1377c334a4a7-0' usage_metadata={'input_tokens': 145, 'output_tokens': 19, 'total_tokens': 164, 'input_token_details': {}, 'output_token_details': {}}\n",
      "content='\\nBefore that, you asked: \"What is my name?\"' additional_kwargs={'refusal': None} response_metadata={'token_usage': {'completion_tokens': 14, 'prompt_tokens': 135, 'total_tokens': 149, 'completion_tokens_details': None, 'prompt_tokens_details': None}, 'model_name': 'thudm/glm-4-32b:free', 'system_fingerprint': None, 'id': 'gen-1748391463-ZvPHOs6CMXIJt22fZwHa', 'finish_reason': 'stop', 'logprobs': None} id='run-fc0fa778-581b-46e5-9d3f-280d271cd2dc-0' usage_metadata={'input_tokens': 135, 'output_tokens': 14, 'total_tokens': 149, 'input_token_details': {}, 'output_token_details': {}}\n",
      "content='\\nYou asked me, \"What is my name?\"' additional_kwargs={'refusal': None} response_metadata={'token_usage': {'completion_tokens': 12, 'prompt_tokens': 172, 'total_tokens': 184, 'completion_tokens_details': None, 'prompt_tokens_details': None}, 'model_name': 'thudm/glm-4-32b:free', 'system_fingerprint': None, 'id': 'gen-1748391467-LuPpmqoO7euV0F8HRYOF', 'finish_reason': 'stop', 'logprobs': None} id='run-14142c07-0692-4905-900e-bd85643fa8a5-0' usage_metadata={'input_tokens': 172, 'output_tokens': 12, 'total_tokens': 184, 'input_token_details': {}, 'output_token_details': {}}\n"
     ]
    }
   ],
   "source": [
    "Alice_config = {\"configurable\": {\"session_id\": \"Alice\"}}\n",
    "res = with_history.invoke(\n",
    "    [HumanMessage(content=\"What is my name?\")],\n",
    "    config=Alice_config\n",
    ")\n",
    "print(res)\n",
    "res = with_history.invoke(\n",
    "    [HumanMessage(content=\"What did I say before?\")],\n",
    "    config=Bob_config\n",
    ")\n",
    "print(res)\n",
    "res = with_history.invoke(\n",
    "    [HumanMessage(content=\"What did I say before?\")],\n",
    "    config=Alice_config\n",
    ")\n",
    "print(res)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22c7d0f5",
   "metadata": {},
   "source": [
    "# Áé∞Âú®‰øùÊåÅ‰∫ÜËÆ∞ÂøÜÔºåÂºïÂÖ•ÊèêÁ§∫ËØçÊ®°Êùø"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "1eb25bd9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Okay, here you go!\n",
      "\n",
      "The square of 5 is **25**.\n"
     ]
    }
   ],
   "source": [
    "from langchain_core.prompts import ChatPromptTemplate, MessagesPlaceholder\n",
    "prompt = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\n",
    "            \"system\",\n",
    "            \"given number {number}, return the square of it.\"\n",
    "        ),\n",
    "        MessagesPlaceholder(variable_name=\"messages\"),\n",
    "    ]\n",
    ")\n",
    "chain = prompt | model | StrOutputParser()\n",
    "print(chain.invoke(\n",
    "    {\n",
    "        \"number\": 5,\n",
    "        \"messages\": [HumanMessage(content=\"Let's go!\")]\n",
    "    }\n",
    "))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c25f551f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
